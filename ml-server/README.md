# ğŸš€ Order AI - PyTorch ML Server

**ì •í™•ë„ ìµœìš°ì„  í’ˆëª© ë§¤ì¹­ ì‹œìŠ¤í…œ (90-95% ëª©í‘œ)**

## ğŸ¯ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” PyTorch + Sentence Transformersë¥¼ ì‚¬ìš©í•˜ì—¬ ì™€ì¸ ë°œì£¼ í…ìŠ¤íŠ¸ë¥¼ í’ˆëª©ì— ë§¤ì¹­í•˜ëŠ” ML ì„œë²„ì…ë‹ˆë‹¤.

### ê¸°ìˆ  ìŠ¤íƒ
- **PyTorch**: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **Sentence Transformers**: ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸
- **FastAPI**: Python ì›¹ í”„ë ˆì„ì›Œí¬
- **Multilingual Model**: í•œêµ­ì–´-ì˜ì–´ ë™ì‹œ ì²˜ë¦¬

## ğŸ“Š ì„±ëŠ¥

| í•­ëª© | ìˆ˜ì¹˜ |
|------|------|
| **ì •í™•ë„** | 90-95% |
| **ì‘ë‹µì†ë„** | 200-500ms |
| **ë©”ëª¨ë¦¬** | 500MB-1GB |
| **ë™ì‹œ ìš”ì²­** | 10-50 req/s |

## ğŸ› ï¸ ì„¤ì¹˜

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
cd ml-server
bash install.sh
```

### 2. English ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ

```bash
source venv/bin/activate
python load_data.py
```

### 3. ì„œë²„ ì‹¤í–‰

**ì˜µì…˜ A: ì§ì ‘ ì‹¤í–‰ (ê°œë°œ)**
```bash
python main.py
```

**ì˜µì…˜ B: PM2ë¡œ ì‹¤í–‰ (í”„ë¡œë•ì…˜)**
```bash
pm2 start ecosystem.config.js
pm2 logs ml-server
```

## ğŸ”§ ì‚¬ìš©ë²•

### API ì—”ë“œí¬ì¸íŠ¸

#### 1. í’ˆëª© ë§¤ì¹­
```bash
POST http://localhost:8000/api/ml-match

{
  "query": "ë°”ë¡¤ë¡œ 3ë³‘",
  "top_k": 5,
  "min_score": 0.3
}
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "query": "ë°”ë¡¤ë¡œ 3ë³‘",
  "results": [
    {
      "item_no": "2118042",
      "item_name": "ì¹´ì‹œë‚˜ ì•„ë¸ë¼ì´ë° ë°”ë¡¤ë¡œ / Cascina Adelaide Barolo (2018)",
      "korean_name": "ì¹´ì‹œë‚˜ ì•„ë¸ë¼ì´ë° ë°”ë¡¤ë¡œ",
      "english_name": "Cascina Adelaide Barolo",
      "vintage": "2018",
      "score": 0.92,
      "method": "pytorch_semantic"
    }
  ],
  "processing_time_ms": 234.5,
  "model_info": {
    "name": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "type": "pytorch",
    "multilingual": "true"
  }
}
```

#### 2. í—¬ìŠ¤ì²´í¬
```bash
GET http://localhost:8000/

{
  "status": "healthy",
  "model": "sentence-transformers/...",
  "items_loaded": 374,
  "embeddings_cached": true
}
```

#### 3. í†µê³„
```bash
GET http://localhost:8000/api/stats

{
  "model_loaded": true,
  "items_count": 374,
  "embeddings_cached": true,
  "cache_size_mb": 48.5
}
```

## ğŸ”„ Next.js í†µí•©

ML ì„œë²„ëŠ” Next.js ë°±ì—”ë“œì—ì„œ ìë™ìœ¼ë¡œ í˜¸ì¶œë©ë‹ˆë‹¤:

```typescript
// app/lib/mlClient.ts
import { mlMatch } from '@/app/lib/mlClient';

const response = await mlMatch({
  query: "ë°”ë¡¤ë¡œ",
  top_k: 5
});
```

### í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ

```
ì‚¬ìš©ì ì…ë ¥
    â†“
Rule-based ë§¤ì¹­ (ë¹ ë¦„, 60-70%)
    â†“ ì ìˆ˜ < 0.7
ML ë§¤ì¹­ (ì •í™•í•¨, 90-95%)
    â†“
ê²°ê³¼ ë°˜í™˜
```

## ğŸ“ˆ ëª¨ë¸ ì •ë³´

### ì‚¬ìš© ëª¨ë¸
- **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**
- ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´, ì˜ì–´ í¬í•¨)
- 384 ì°¨ì› ì„ë² ë”©
- 120M íŒŒë¼ë¯¸í„°

### ëŒ€ì•ˆ ëª¨ë¸

**í•œêµ­ì–´ íŠ¹í™”:**
```python
model = SentenceTransformer('jhgan/ko-sroberta-multitask')
```

**ë” í° ëª¨ë¸ (ë” ì •í™•):**
```python
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
```

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')
```

### 2. ëŠë¦° ì‘ë‹µ
```bash
# GPU ì‚¬ìš© (CUDA ì„¤ì¹˜ í•„ìš”)
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
python -c "from sentence_transformers import SentenceTransformer; model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ì„ë² ë”© ìºì‹±
ëª¨ë“  í’ˆëª©ì˜ ì„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ì— ìºì‹œí•©ë‹ˆë‹¤.

### 2. ë°°ì¹˜ ì²˜ë¦¬
ì—¬ëŸ¬ ìš”ì²­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ì—¬ GPU íš¨ìœ¨ í–¥ìƒ.

### 3. ëª¨ë¸ ì–‘ìí™”
ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ëª¨ë¸ì„ INT8ë¡œ ì–‘ìí™” ê°€ëŠ¥.

## ğŸ” í™˜ê²½ ë³€ìˆ˜

```bash
# .env
ML_SERVER_URL=http://localhost:8000
DB_PATH=../data.sqlite3
```

## ğŸ“ ë¡œê·¸

ë¡œê·¸ëŠ” `ml-server/logs/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:
- `ml-error.log`: ì—ëŸ¬ ë¡œê·¸
- `ml-out.log`: ì¼ë°˜ ë¡œê·¸

## ğŸš€ ë°°í¬

### Railway
```bash
# railway.json
{
  "build": {
    "command": "pip install -r requirements.txt"
  },
  "start": {
    "command": "python main.py"
  }
}
```

### Render
```yaml
# render.yaml
services:
  - type: web
    name: ml-server
    env: python
    buildCommand: pip install -r requirements.txt
    startCommand: python main.py
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [Sentence Transformers ë¬¸ì„œ](https://www.sbert.net/)
- [FastAPI ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [PyTorch ë¬¸ì„œ](https://pytorch.org/docs/)

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License
