# ğŸ§  PyTorch ê¸°ë°˜ í’ˆëª© ë§¤ì¹­ í•™ìŠµ ì‹œìŠ¤í…œ ì„¤ê³„

## ğŸ¯ **ì™œ PyTorchì¸ê°€?**

### **ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„**
```
ê·œì¹™ ê¸°ë°˜:
- "ch" â†’ "ì°°ìŠ¤í•˜ì´ì§" (í•˜ë“œì½”ë”©)
- "bl" â†’ "ë¡œì‰¬ë²¨ë Œ" (í•˜ë“œì½”ë”©)
- ìƒˆë¡œìš´ ì•½ì–´ë§ˆë‹¤ ìˆ˜ë™ ë§¤í•‘ í•„ìš” âŒ

ì ìˆ˜ ê³„ì‚°:
- ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (ê³ ì •ëœ ì•Œê³ ë¦¬ì¦˜)
- í•™ìŠµì´ ìŒ“ì—¬ë„ ì•Œê³ ë¦¬ì¦˜ ìì²´ëŠ” ê°œì„  ì•ˆë¨ âŒ
```

### **PyTorch ê¸°ë°˜ì˜ ì¥ì **
```
ì„ë² ë”© í•™ìŠµ:
- "ch", "ì°°ìŠ¤í•˜ì´ì§", "Charles Heidsieck" ëª¨ë‘ ê°™ì€ ë²¡í„° ê³µê°„ì— ë§¤í•‘
- ìƒˆë¡œìš´ ì•½ì–´ë„ ìë™ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚° âœ…

ëª¨ë¸ í•™ìŠµ:
- ì‚¬ìš©ì ì„ íƒ ë°ì´í„°ë¡œ ëª¨ë¸ ìì²´ê°€ ê°œì„ ë¨
- í•™ìŠµ ìŒ“ì¼ìˆ˜ë¡ ëª¨ë¸ì´ ì ì  ë˜‘ë˜‘í•´ì§ âœ…

íŒ¨í„´ ì¸ì‹:
- "ch ìƒ¤ë¥´ë„ë„¤"ì™€ "ch ê¹Œë² "ê°€ ë‹¤ë¥¸ ê²°ê³¼ì„ì„ ìë™ í•™ìŠµ
- ì»¨í…ìŠ¤íŠ¸ ì´í•´ ëŠ¥ë ¥ âœ…
```

---

## ğŸ—ï¸ **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜**

### **ì „ì²´ êµ¬ì¡°**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ì…ë ¥ ë ˆì´ì–´                            â”‚
â”‚  ì‚¬ìš©ì ì…ë ¥: "ch ìƒ¤ë¥´ë„ë„¤ 24ë³‘"                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ì „ì²˜ë¦¬ & í† í°í™”                             â”‚
â”‚  - ìˆ˜ëŸ‰ ì œê±°: "ch ìƒ¤ë¥´ë„ë„¤"                              â”‚
â”‚  - í† í° ë¶„í•´: ["ch", "ìƒ¤ë¥´ë„ë„¤"]                         â”‚
â”‚  - ì •ê·œí™”: ì†Œë¬¸ì ë³€í™˜, ê³µë°± ì •ë¦¬                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PyTorch ì„ë² ë”© ë ˆì´ì–´ ğŸ§                         â”‚
â”‚  Token â†’ Vector ë³€í™˜                                     â”‚
â”‚  - "ch" â†’ [0.23, -0.45, 0.78, ...]  (128ì°¨ì›)          â”‚
â”‚  - "ìƒ¤ë¥´ë„ë„¤" â†’ [0.12, 0.67, -0.34, ...]                â”‚
â”‚  - "ì°°ìŠ¤í•˜ì´ì§" â†’ [0.25, -0.43, 0.81, ...]  (chì™€ ìœ ì‚¬!) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ìœ ì‚¬ë„ ê³„ì‚° ë ˆì´ì–´                             â”‚
â”‚  ì…ë ¥ ì„ë² ë”© vs í’ˆëª© ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„                â”‚
â”‚  - ["ch", "ìƒ¤ë¥´ë„ë„¤"] vs "ì°°ìŠ¤í•˜ì´ì§ ìƒ¤ë¥´ë„ë„¤" â†’ 0.92   â”‚
â”‚  - ["ch", "ìƒ¤ë¥´ë„ë„¤"] vs "ìƒ¤ë˜ ìƒ¤ë¥´ë„ë„¤" â†’ 0.45         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ë­í‚¹ ëª¨ë¸ (Neural Network) ğŸ§                   â”‚
â”‚  Input: [ìœ ì‚¬ë„, ìµœê·¼êµ¬ë§¤, êµ¬ë§¤ë¹ˆë„, ë¹ˆí‹°ì§€, ...]        â”‚
â”‚  Hidden Layers: 128 â†’ 64 â†’ 32                           â”‚
â”‚  Output: ìµœì¢… ì ìˆ˜ (0~1)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ê²°ê³¼ + í•™ìŠµ í”¼ë“œë°±                          â”‚
â”‚  ì‚¬ìš©ì ì„ íƒ â†’ ëª¨ë¸ í•™ìŠµ (Backpropagation)               â”‚
â”‚  - ì„ íƒëœ í’ˆëª©: Positive label (1.0)                     â”‚
â”‚  - ë¬´ì‹œëœ í’ˆëª©: Negative label (0.0)                     â”‚
â”‚  - Loss ê³„ì‚° â†’ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ **í•µì‹¬ ëª¨ë¸: Dual-Encoder Architecture**

### **1. Query Encoder (ì…ë ¥ ì¸ì½”ë”)**
```python
class QueryEncoder(nn.Module):
    def __init__(self, vocab_size, embed_dim=128):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, embed_dim, batch_first=True)
        self.fc = nn.Linear(embed_dim, embed_dim)
        
    def forward(self, tokens):
        # tokens: ["ch", "ìƒ¤ë¥´ë„ë„¤"] â†’ [token_ids]
        embedded = self.embedding(tokens)  # [batch, seq_len, embed_dim]
        _, (hidden, _) = self.lstm(embedded)  # [1, batch, embed_dim]
        query_vec = self.fc(hidden.squeeze(0))  # [batch, embed_dim]
        return query_vec  # ì…ë ¥ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•
```

### **2. Item Encoder (í’ˆëª© ì¸ì½”ë”)**
```python
class ItemEncoder(nn.Module):
    def __init__(self, vocab_size, embed_dim=128):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, embed_dim, batch_first=True)
        self.fc = nn.Linear(embed_dim, embed_dim)
        
    def forward(self, tokens):
        # tokens: "ì°°ìŠ¤í•˜ì´ì§ ìƒ¤ë¥´ë„ë„¤ 2022" â†’ [token_ids]
        embedded = self.embedding(tokens)
        _, (hidden, _) = self.lstm(embedded)
        item_vec = self.fc(hidden.squeeze(0))
        return item_vec  # í’ˆëª©ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•
```

### **3. Similarity + Ranking Model**
```python
class ItemMatchingModel(nn.Module):
    def __init__(self, vocab_size, embed_dim=128):
        super().__init__()
        self.query_encoder = QueryEncoder(vocab_size, embed_dim)
        self.item_encoder = ItemEncoder(vocab_size, embed_dim)
        
        # ì¶”ê°€ ì‹œê·¸ë„ í†µí•© (êµ¬ë§¤ ì´ë ¥, ë¹ˆí‹°ì§€ ë“±)
        self.ranker = nn.Sequential(
            nn.Linear(embed_dim + 5, 64),  # embed + 5ê°œ ì¶”ê°€ íŠ¹ì§•
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()  # 0~1 ì ìˆ˜
        )
    
    def forward(self, query_tokens, item_tokens, features):
        # ì„ë² ë”© ê³„ì‚°
        query_vec = self.query_encoder(query_tokens)
        item_vec = self.item_encoder(item_tokens)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarity = F.cosine_similarity(query_vec, item_vec, dim=1)
        
        # ì¶”ê°€ íŠ¹ì§•ê³¼ ê²°í•©
        # features: [recent_purchase, frequency, vintage, ...]
        combined = torch.cat([query_vec, features], dim=1)
        
        # ìµœì¢… ì ìˆ˜
        score = self.ranker(combined)
        return score, similarity
```

---

## ğŸ“Š **í•™ìŠµ í”„ë¡œì„¸ìŠ¤**

### **1. ì´ˆê¸° ë°ì´í„° ì¤€ë¹„**
```python
# ê¸°ì¡´ ê±°ë˜ ì´ë ¥ìœ¼ë¡œ ì´ˆê¸° í•™ìŠµ
training_data = [
    {
        "query": "ch ìƒ¤ë¥´ë„ë„¤",
        "positive_item": "3A24401 ì°°ìŠ¤í•˜ì´ì§ ìƒ¤ë¥´ë„ë„¤ 2022",
        "negative_items": [
            "3B12345 ìƒ¤ë˜ ìƒ¤ë¥´ë„ë„¤ 2021",
            "3C67890 ë¡œì œ ìƒ¤ë¥´ë„ë„¤ 2020"
        ],
        "features": {
            "recent_purchase": 0.8,
            "frequency": 0.9,
            "vintage": 0.7
        }
    },
    # ... ë” ë§ì€ ë°ì´í„°
]
```

### **2. í•™ìŠµ ë£¨í”„**
```python
def train_epoch(model, dataloader, optimizer, criterion):
    model.train()
    total_loss = 0
    
    for batch in dataloader:
        query_tokens = batch['query_tokens']
        positive_item = batch['positive_item']
        negative_items = batch['negative_items']
        features = batch['features']
        
        # Positive ì˜ˆì¸¡
        pos_score, pos_sim = model(query_tokens, positive_item, features)
        
        # Negative ì˜ˆì¸¡ë“¤
        neg_scores = []
        for neg_item in negative_items:
            neg_score, _ = model(query_tokens, neg_item, features)
            neg_scores.append(neg_score)
        
        # Triplet Loss or Contrastive Loss
        # PositiveëŠ” 1ì— ê°€ê¹ê²Œ, NegativeëŠ” 0ì— ê°€ê¹ê²Œ
        loss = criterion(pos_score, torch.ones_like(pos_score))
        for neg_score in neg_scores:
            loss += criterion(neg_score, torch.zeros_like(neg_score))
        
        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(dataloader)
```

### **3. ì‹¤ì‹œê°„ í•™ìŠµ (Online Learning)**
```python
def update_model_with_user_selection(
    model, 
    query: str, 
    selected_item: str,
    rejected_items: List[str]
):
    """
    ì‚¬ìš©ìê°€ í›„ë³´ë¥¼ ì„ íƒí•  ë•Œë§ˆë‹¤ ëª¨ë¸ ì—…ë°ì´íŠ¸
    """
    model.train()
    
    # ë°ì´í„° ì¤€ë¹„
    query_tokens = tokenize(query)
    selected_tokens = tokenize(selected_item)
    
    # Forward
    score, _ = model(query_tokens, selected_tokens, features)
    
    # Loss (ì„ íƒëœ í’ˆëª©ì€ 1.0ì— ê°€ê¹Œì›Œì•¼ í•¨)
    loss = F.binary_cross_entropy(score, torch.tensor([1.0]))
    
    # ê±°ë¶€ëœ í’ˆëª©ë“¤ì€ 0.0ì— ê°€ê¹Œì›Œì•¼ í•¨
    for rejected in rejected_items:
        rejected_tokens = tokenize(rejected)
        rej_score, _ = model(query_tokens, rejected_tokens, features)
        loss += F.binary_cross_entropy(rej_score, torch.tensor([0.0]))
    
    # Backprop
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # ëª¨ë¸ ì €ì¥ (ì£¼ê¸°ì ìœ¼ë¡œ)
    if should_save():
        torch.save(model.state_dict(), 'model_weights.pth')
```

---

## ğŸš€ **ì‹œìŠ¤í…œ í†µí•© (TypeScript + Python)**

### **ì•„í‚¤í…ì²˜**
```
TypeScript (Hono)
    â†“ HTTP Request
Python FastAPI
    â†“
PyTorch Model
    â†“ ì˜ˆì¸¡ ê²°ê³¼
TypeScript
```

### **1. Python API ì„œë²„ (FastAPI)**
```python
# app/ml/api.py
from fastapi import FastAPI
from pydantic import BaseModel
import torch

app = FastAPI()

# ëª¨ë¸ ë¡œë“œ
model = ItemMatchingModel.load('model_weights.pth')
model.eval()

class PredictRequest(BaseModel):
    query: str
    candidate_items: List[str]
    features: Dict[str, float]

@app.post("/predict")
async def predict(request: PredictRequest):
    query_tokens = tokenize(request.query)
    
    results = []
    for item in request.candidate_items:
        item_tokens = tokenize(item)
        features = torch.tensor([request.features.values()])
        
        with torch.no_grad():
            score, similarity = model(query_tokens, item_tokens, features)
        
        results.append({
            "item": item,
            "score": float(score),
            "similarity": float(similarity)
        })
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    results.sort(key=lambda x: x['score'], reverse=True)
    return {"predictions": results}

@app.post("/learn")
async def learn(request: LearnRequest):
    """ì‚¬ìš©ì ì„ íƒ ì‹œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
    update_model_with_user_selection(
        model,
        request.query,
        request.selected_item,
        request.rejected_items
    )
    return {"status": "learned"}
```

### **2. TypeScript í†µí•©**
```typescript
// app/lib/mlPredictor.ts
export async function predictWithML(
  query: string,
  candidates: Array<{ item_no: string; item_name: string }>,
  features: {
    recentPurchase: number;
    frequency: number;
    vintage: number;
  }
): Promise<Array<{ item_no: string; item_name: string; score: number }>> {
  
  // Python API í˜¸ì¶œ
  const response = await fetch('http://localhost:8000/predict', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      query,
      candidate_items: candidates.map(c => c.item_name),
      features
    })
  });
  
  const result = await response.json();
  
  // ê²°ê³¼ ë§¤í•‘
  return result.predictions.map((pred: any, idx: number) => ({
    ...candidates[idx],
    score: pred.score
  }));
}

// ì‚¬ìš©ì ì„ íƒ ì‹œ í•™ìŠµ
export async function learnFromSelection(
  query: string,
  selectedItem: string,
  rejectedItems: string[]
) {
  await fetch('http://localhost:8000/learn', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      query,
      selected_item: selectedItem,
      rejected_items: rejectedItems
    })
  });
}
```

### **3. resolveItemsWeighted.ts í†µí•©**
```typescript
// app/lib/resolveItemsWeighted.ts
import { predictWithML, learnFromSelection } from './mlPredictor';

export function resolveItemsByClientWeighted(...) {
  return items.map(async (it) => {
    // ê¸°ì¡´ í›„ë³´ í’€ êµ¬ì¶•
    const pool = [...clientRows, ...masterRows, ...englishRows];
    
    // ğŸ§  PyTorch ëª¨ë¸ë¡œ ì˜ˆì¸¡
    const mlPredictions = await predictWithML(
      it.name,
      pool,
      {
        recentPurchase: getRecentPurchaseScore(clientCode, item_no),
        frequency: getFrequencyScore(clientCode, item_no),
        vintage: getVintageScore(it.name, item_no)
      }
    );
    
    // ML ì ìˆ˜ì™€ ê¸°ì¡´ ì ìˆ˜ ê²°í•© (ì•™ìƒë¸”)
    const finalScored = mlPredictions.map(pred => {
      const baseScore = calculateBaseScore(it.name, pred.item_name);
      const mlScore = pred.score;
      
      // ê°€ì¤‘ í‰ê·  (ML 70%, ê¸°ì¡´ 30%)
      const finalScore = mlScore * 0.7 + baseScore * 0.3;
      
      return {
        ...pred,
        score: finalScore
      };
    });
    
    // ... ì •ë ¬ ë° ë°˜í™˜
  });
}
```

---

## ğŸ“ˆ **ì‹œê°„ì— ë”°ë¥¸ ì„±ëŠ¥ ê°œì„ **

### **ì´ˆê¸° (í•™ìŠµ ë°ì´í„° 0~100ê±´)**
```
ì •í™•ë„: 60%
- ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œê³¼ ë¹„ìŠ·
- ì•„ì§ í•™ìŠµ ë¶€ì¡±
```

### **ì¤‘ê¸° (í•™ìŠµ ë°ì´í„° 100~1000ê±´)**
```
ì •í™•ë„: 80%
- ìì£¼ ì“°ëŠ” ì•½ì–´ íŒ¨í„´ í•™ìŠµë¨
- "ch" â†’ "ì°°ìŠ¤í•˜ì´ì§" ì—°ê´€ì„± ì´í•´
- ì»¨í…ìŠ¤íŠ¸ êµ¬ë¶„ ì‹œì‘
```

### **ì¥ê¸° (í•™ìŠµ ë°ì´í„° 1000ê±´+)**
```
ì •í™•ë„: 95%+
- ìƒˆë¡œìš´ ì•½ì–´ë„ ìœ ì‚¬ íŒ¨í„´ìœ¼ë¡œ ì¶”ë¡ 
- "sh" ì…ë ¥ â†’ "ìƒ¤ë˜"ë¡œ ì¶”ë¡  (chì™€ ìœ ì‚¬ íŒ¨í„´)
- ì‚¬ìš©ì ìŠµê´€ í•™ìŠµ (íŠ¹ì • ê±°ë˜ì²˜ëŠ” íŠ¹ì • íŒ¨í„´ ì„ í˜¸)
```

---

## âš¡ **êµ¬í˜„ ë‹¨ê³„**

### **Phase 1: ì¸í”„ë¼ êµ¬ì¶• (1ì£¼)**
1. Python í™˜ê²½ ì„¤ì •
2. PyTorch ì„¤ì¹˜
3. FastAPI ì„œë²„ êµ¬ì¶•
4. TypeScript â†” Python í†µì‹  í…ŒìŠ¤íŠ¸

### **Phase 2: ëª¨ë¸ ê°œë°œ (2ì£¼)**
1. ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
2. ì„ë² ë”© ëª¨ë¸ êµ¬í˜„
3. ë­í‚¹ ëª¨ë¸ êµ¬í˜„
4. ì´ˆê¸° í•™ìŠµ (ê¸°ì¡´ ê±°ë˜ ì´ë ¥ í™œìš©)

### **Phase 3: í†µí•© (1ì£¼)**
1. resolveItemsWeighted í†µí•©
2. ì‹¤ì‹œê°„ í•™ìŠµ API ì—°ê²°
3. ëª¨ë¸ ì €ì¥/ë¡œë“œ ì‹œìŠ¤í…œ

### **Phase 4: ìµœì í™” (ì§€ì†)**
1. ë°°ì¹˜ í•™ìŠµ ìŠ¤ì¼€ì¤„ë§
2. ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
3. A/B í…ŒìŠ¤íŠ¸
4. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

---

## ğŸ¯ **PyTorchì˜ í•µì‹¬ ì´ì **

1. **ìë™ íŒ¨í„´ í•™ìŠµ**
   - "ch", "bl", "lc" íŒ¨í„´ì„ ìë™ ì¸ì‹
   - ìƒˆë¡œìš´ ì•½ì–´ë„ ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ë¡ 

2. **ì§€ì†ì  ê°œì„ **
   - ì‚¬ìš©ì ì„ íƒë§ˆë‹¤ ëª¨ë¸ ì—…ë°ì´íŠ¸
   - í•™ìŠµ ìŒ“ì¼ìˆ˜ë¡ ë˜‘ë˜‘í•´ì§

3. **ì»¨í…ìŠ¤íŠ¸ ì´í•´**
   - "ch ìƒ¤ë¥´ë„ë„¤"ì™€ "ch ê¹Œë² " êµ¬ë¶„
   - í’ˆì¢… + ìƒì‚°ì ì¡°í•© í•™ìŠµ

4. **ì „ì´ í•™ìŠµ**
   - í•œ ê±°ë˜ì²˜ í•™ìŠµì´ ë‹¤ë¥¸ ê±°ë˜ì²˜ì—ë„ ì ìš©
   - ë„ë©”ì¸ ì§€ì‹ ëˆ„ì 

---

**ì´ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ì–´ìš”?** ğŸš€

ê°•ë ¥í•˜ì§€ë§Œ êµ¬í˜„ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤:
- Phase 1-3: ì•½ 4ì£¼
- íš¨ê³¼ ì²´ê°: í•™ìŠµ ë°ì´í„° 100ê±´+ ë¶€í„°
- ì¥ê¸°ì ìœ¼ë¡œ ê°€ì¥ ê°•ë ¥í•œ ì‹œìŠ¤í…œ!
