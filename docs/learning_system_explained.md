# 🎯 품목 학습 시스템 - 점수 계산 메커니즘

## 📊 **전체 점수 계산 공식**

```
최종 점수 = (기본점수 × 1.0) 
          + (사용자학습 × 3.0) 
          + (최근구매 × 2.0) 
          + (구매빈도 × 1.5) 
          + (빈티지 × 1.0)
```

---

## 🎓 **1. 사용자 학습 신호 (가중치: 3.0배 - 가장 중요!)**

### **학습 데이터 저장 구조**
```sql
-- item_alias 테이블
alias          canonical     count    last_used_at
-------------------------------------------------
"ch"           "3A24401"     1        2024-01-08
"찰스하이직"    "3A24401"     3        2024-01-08
"bl"           "3B12345"     2        2024-01-08
"로쉬벨렌"     "3B12345"     1        2024-01-08
```

### **점수 계산 메커니즘**

#### **Case 1: Exact 매칭 (정확히 일치)**
```
입력: "ch 샤르도네 24병"
학습된 별칭: "ch" → "3A24401"

정규화 후:
- 입력: "ch샤르도네" (수량 제거)
- 별칭: "ch"

매칭 결과: "ch샤르도네".includes("ch") ✅

점수:
- 1회 학습: +0.20 × 3.0 = +0.60
- 2회 학습: +0.30 × 3.0 = +0.90
- 3회+ 학습: +0.40 × 3.0 = +1.20
```

#### **Case 2: Contains_Specific (포함 매칭 - 구체적 별칭)**
```
입력: "찰스하이직 샤르도네 24병"
학습된 별칭: "찰스하이직" → "3A24401"

조건:
- 별칭이 3개 이상의 토큰 OR 12자 이상
- "찰스하이직" = 5자 (토큰 1개) → specific 아님

점수:
- 1회 학습: +0.20 × 3.0 = +0.60
- 2회 학습: +0.30 × 3.0 = +0.90
- 3회+ 학습: +0.40 × 3.0 = +1.20
```

#### **Case 3: Contains_Weak (포함 매칭 - 약한 별칭)**
```
입력: "ch 샤르도네 24병"
학습된 별칭: "ch" → "3A24401"

조건:
- 별칭이 짧음 (3개 미만 토큰 AND 12자 미만)
- "ch" = 2자 (토큰 1개) → weak

점수 (절반만 적용):
- 1회 학습: +0.20 × 0.5 × 3.0 = +0.30
- 2회 학습: +0.30 × 0.5 × 3.0 = +0.45
- 3회+ 학습: +0.40 × 0.5 × 3.0 = +0.60
```

---

## 📈 **2. 다른 신호들 (참고)**

### **최근 구매 신호 (가중치: 2.0배)**
```
7일 이내:  +0.20 × 2.0 = +0.40
30일 이내: +0.15 × 2.0 = +0.30
90일 이내: +0.10 × 2.0 = +0.20
90일 이상: +0.05 × 2.0 = +0.10
```

### **구매 빈도 신호 (가중치: 1.5배)**
```
10회 이상: +0.15 × 1.5 = +0.225
5~9회:     +0.10 × 1.5 = +0.150
2~4회:     +0.05 × 1.5 = +0.075
1회:       +0.02 × 1.5 = +0.030
```

### **빈티지 신호 (가중치: 1.0배)**
```
빈티지 일치: +0.08 × 1.0 = +0.08
빈티지 불일치: -0.18 × 1.0 = -0.18
최신 빈티지: +0.20 × 1.0 = +0.20
1년 전: +0.15 × 1.0 = +0.15
2년 전: +0.10 × 1.0 = +0.10
3년+ 전: +0.05 × 1.0 = +0.05
```

---

## 🎯 **실전 시나리오: 생산자 약어 학습**

### **시나리오 1: 찰스하이직 > ch**

#### **학습 전**
```
입력: "ch 샤르도네 24병"

후보 1: 찰스하이직 샤르도네 2022
- 기본 점수: 0.60 (문자열 유사도 낮음)
- 최근 구매: +0.40 (7일 이내 구매)
- 구매 빈도: +0.15 (10회 이상)
- 최종 점수: 0.60 + 0.40 + 0.15 = 1.15

후보 2: 샤또 샤르도네 2021
- 기본 점수: 0.85 (샤르도네 매칭)
- 최종 점수: 0.85
```

**결과**: 샤또 샤르도네가 1위 (잘못된 인식) ❌

#### **학습 후 (1회 학습)**
```
입력: "ch 샤르도네 24병"
학습: "ch" → "3A24401 찰스하이직 샤르도네"

후보 1: 찰스하이직 샤르도네 2022
- 기본 점수: 0.60
- 사용자 학습: +0.60 (1회 학습, weak)  ← ✨ 학습 보너스!
- 최근 구매: +0.40
- 구매 빈도: +0.15
- 최종 점수: 0.60 + 0.60 + 0.40 + 0.15 = 1.75

후보 2: 샤또 샤르도네 2021
- 기본 점수: 0.85
- 최종 점수: 0.85
```

**결과**: 찰스하이직이 1위 (올바른 인식) ✅
**점수 차이**: 1.75 - 0.85 = **0.90** (자동 확정!)

#### **학습 후 (3회+ 학습)**
```
후보 1: 찰스하이직 샤르도네 2022
- 기본 점수: 0.60
- 사용자 학습: +1.20 (3회+ 학습, weak)  ← ✨✨ 강력한 보너스!
- 최근 구매: +0.40
- 구매 빈도: +0.15
- 최종 점수: 0.60 + 1.20 + 0.40 + 0.15 = 2.35
```

**결과**: **압도적 1위** (자동 확정 보장) ✅

---

### **시나리오 2: 로쉬벨렌 > bl**

#### **학습 전**
```
입력: "bl 피노누아 24병"

후보 1: 로쉬벨렌 피노누아 2021
- 기본 점수: 0.55 (bl 매칭 없음)
- 최종 점수: 0.55

후보 2: 블랑빌 피노누아 2022
- 기본 점수: 0.80 ("bl" → "블랑" 부분 매칭)
- 최종 점수: 0.80
```

**결과**: 블랑빌이 1위 (잘못된 인식) ❌

#### **학습 후 (2회 학습)**
```
입력: "bl 피노누아 24병"
학습: "bl" → "3B12345 로쉬벨렌 피노누아"

후보 1: 로쉬벨렌 피노누아 2021
- 기본 점수: 0.55
- 사용자 학습: +0.45 (2회 학습, weak)  ← ✨ 학습 보너스!
- 최종 점수: 0.55 + 0.45 = 1.00

후보 2: 블랑빌 피노누아 2022
- 기본 점수: 0.80
- 최종 점수: 0.80
```

**결과**: 로쉬벨렌이 1위 (올바른 인식) ✅

---

## ⚡ **즉시 확정 규칙 (Hard Resolution)**

### **Case 1: Exact 매칭 (score 1.0)**
```
학습: "ch" → "3A24401"
입력: "ch" (정확히 일치)

→ score 1.0으로 즉시 확정 (다른 후보 무시)
```

### **Case 2: Contains_Specific 매칭 (score 0.99)**
```
학습: "찰스하이직 샤르도네" → "3A24401"
입력: "찰스하이직 샤르도네 리저브"

→ score 0.99로 즉시 확정 (다른 후보 무시)
```

---

## 🎓 **학습 전략 권장사항**

### **1. 짧은 약어 학습**
```
✅ 추천: "ch" → "찰스하이직 샤르도네"
✅ 추천: "bl" → "로쉬벨렌 피노누아"
✅ 추천: "lc" → "레이크 찰리스"

→ weak 매칭이지만 3회+ 학습 시 +1.20 보너스
→ 자주 사용하는 약어는 점수가 크게 상승
```

### **2. 구체적인 별칭 학습 (더 강력)**
```
✅ 최고: "찰스하이직 샤르도네" → "3A24401"
✅ 최고: "로쉬벨렌 피노누아 리저브" → "3B12345"

→ specific 매칭으로 full 보너스 적용
→ 3회+ 학습 시 +1.20 보너스 (weak의 2배 효과)
```

### **3. 반복 학습의 위력**
```
1회 학습: +0.60 ~ +0.90
2회 학습: +0.90 ~ +1.35
3회+ 학습: +1.20 ~ +1.80

→ 자주 사용하는 품목/약어는 반복 학습 권장!
```

---

## 🔍 **디버깅: 학습이 제대로 작동하는지 확인**

### **1. D1 데이터베이스 확인**
```bash
npm run db:console:local
> SELECT * FROM item_alias ORDER BY count DESC;

# 출력 예시:
alias          canonical     count    last_used_at
-------------------------------------------------
"ch"           "3A24401"     3        2024-01-08 10:30:00
"bl"           "3B12345"     2        2024-01-08 09:15:00
```

### **2. 점수 디버그 로그 확인**
```bash
pm2 logs order-ai --nostream --lines 50 | grep -E '(학습|_debug|userLearning)'
```

### **3. 실제 점수 확인**
```
발주 생성 후 후보 목록에서:
- _debug.userLearning: 학습 보너스 점수
- _debug.baseScore: 기본 문자열 유사도
- _debug.weights: 각 신호의 가중치 적용 결과
```

---

## ✅ **요약**

### **생산자 약어 학습의 효과**
1. **"ch" → "찰스하이직"**: 
   - 1회 학습: +0.60 보너스
   - 3회+ 학습: +1.20 보너스 (압도적 우위)

2. **"bl" → "로쉬벨렌"**: 
   - weak 매칭이지만 반복 학습으로 강력한 효과
   - 3회+ 학습 시 다른 후보들을 압도

3. **학습 누적의 중요성**:
   - 사용자 학습 신호는 **가중치 3.0배** (가장 중요)
   - 반복 학습으로 보너스가 기하급수적으로 증가
   - 3회+ 학습 시 거의 모든 경우에 1위 보장

**핵심 메시지**: **자주 사용하는 약어/별칭을 반복 학습하면 시스템이 점점 더 정확해집니다!** 🎯
