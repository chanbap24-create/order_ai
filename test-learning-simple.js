/**
 * ========================================
 * í•™ìŠµ ì‹œìŠ¤í…œ ê°„ë‹¨ í…ŒìŠ¤íŠ¸
 * ========================================
 */

const Database = require('better-sqlite3');
const db = new Database('data.sqlite3', { readonly: true });

console.log('=== ğŸ§ª í•™ìŠµ ë°ì´í„° ê²€ì¦ ===\n');

// 1. í† í° ë§¤í•‘ í†µê³„
console.log('ğŸ“Š 1. í† í° ë§¤í•‘ í†µê³„');
console.log('â”€'.repeat(60));

const tokenCount = db.prepare('SELECT COUNT(*) as cnt FROM token_mapping').get();
console.log(`ì´ í† í°: ${tokenCount.cnt}ê°œ\n`);

const tokenTypes = db.prepare(`
  SELECT token_type, COUNT(*) as cnt
  FROM token_mapping
  GROUP BY token_type
  ORDER BY cnt DESC
`).all();

tokenTypes.forEach(t => {
  console.log(`  ${t.token_type}: ${t.cnt}ê°œ`);
});

// 2. í’ˆëª© ë³„ì¹­ í†µê³„
console.log('\n\nğŸ“ 2. í’ˆëª© ë³„ì¹­ í†µê³„');
console.log('â”€'.repeat(60));

const aliasCount = db.prepare('SELECT COUNT(*) as cnt FROM item_alias').get();
console.log(`ì´ ë³„ì¹­: ${aliasCount.cnt}ê°œ\n`);

const topAliases = db.prepare(`
  SELECT alias, canonical, count
  FROM item_alias
  WHERE length(alias) <= 3
  ORDER BY count DESC
  LIMIT 20
`).all();

console.log('ì¸ê¸° ë³„ì¹­ TOP 20:');
topAliases.forEach((a, idx) => {
  console.log(`  ${idx + 1}. ${a.alias.padEnd(5)} â†’ ${a.canonical.padEnd(30)} (${a.count}íšŒ)`);
});

// 3. íŠ¹ì • í’ˆëª©ì˜ í† í° ë§¤í•‘ ì¡°íšŒ
console.log('\n\nğŸ” 3. íŠ¹ì • í’ˆëª© í† í° ì¡°íšŒ (ì°°ìŠ¤ í•˜ì´ì§)');
console.log('â”€'.repeat(60));

const charlesTokens = db.prepare(`
  SELECT token, mapped_text, token_type, learned_count
  FROM token_mapping
  WHERE mapped_text LIKE '00NV%'
    AND (token LIKE '%ì°°ìŠ¤%' OR token LIKE '%í•˜ì´ì§%' OR token LIKE '%charles%' OR token LIKE '%heidsieck%')
  ORDER BY learned_count DESC
  LIMIT 10
`).all();

charlesTokens.forEach(t => {
  console.log(`  ${t.token} â†’ ${t.mapped_text} (íƒ€ì…: ${t.token_type}, ë¹ˆë„: ${t.learned_count})`);
});

// 4. í•™ìŠµ ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ë§¤ì¹­)
console.log('\n\nğŸ¯ 4. ê°„ë‹¨ ë§¤ì¹­ í…ŒìŠ¤íŠ¸');
console.log('â”€'.repeat(60));

const testQueries = [
  { alias: 'ch', expected: 'ì°°ìŠ¤ í•˜ì´ì§' },
  { alias: 'va', expected: 'ëµˆë¸Œ ì•”ë°œ' },
  { alias: 'rf', expected: 'ë¼í”¼ë‹ˆ' },
  { alias: 'vg', expected: 'ë±…ìƒ ì§€ë¼ë¥´ëŒ•' },
];

testQueries.forEach(test => {
  const result = db.prepare(`
    SELECT canonical, count
    FROM item_alias
    WHERE alias = ? COLLATE NOCASE
  `).get(test.alias);
  
  if (result) {
    const match = result.canonical === test.expected ? 'âœ…' : 'âš ï¸';
    console.log(`  ${match} "${test.alias}" â†’ "${result.canonical}" (ì˜ˆìƒ: "${test.expected}", ì‚¬ìš©: ${result.count}íšŒ)`);
  } else {
    console.log(`  âŒ "${test.alias}" â†’ ë§¤ì¹­ ì—†ìŒ (ì˜ˆìƒ: "${test.expected}")`);
  }
});

// 5. í† í°ìœ¼ë¡œ í’ˆëª© ì—­ê²€ìƒ‰
console.log('\n\nğŸ” 5. í† í° ì—­ê²€ìƒ‰ í…ŒìŠ¤íŠ¸');
console.log('â”€'.repeat(60));

const tokenSearches = [
  'ì°°ìŠ¤',
  'í•˜ì´ì§',
  'ë¸Œë¥',
  'ë¼í”¼ë‹ˆ',
];

tokenSearches.forEach(token => {
  const results = db.prepare(`
    SELECT DISTINCT mapped_text, COUNT(*) as match_count
    FROM token_mapping
    WHERE token = ? COLLATE NOCASE
    GROUP BY mapped_text
    ORDER BY match_count DESC
    LIMIT 3
  `).all(token);
  
  if (results.length > 0) {
    console.log(`\n  "${token}" ê²€ìƒ‰ ê²°ê³¼:`);
    results.forEach((r, idx) => {
      // í’ˆëª©ëª… ì¡°íšŒ
      const itemName = db.prepare(`
        SELECT name_en
        FROM item_english
        WHERE item_no = ?
      `).get(r.mapped_text);
      
      console.log(`    ${idx + 1}. ${r.mapped_text}: ${itemName ? itemName.name_en : '(ì—†ìŒ)'}`);
    });
  } else {
    console.log(`\n  "${token}": ê²°ê³¼ ì—†ìŒ`);
  }
});

db.close();

console.log('\n\nâœ… ê²€ì¦ ì™„ë£Œ!\n');
